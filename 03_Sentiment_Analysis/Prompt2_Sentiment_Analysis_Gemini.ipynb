{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy9ROy-SV-U8"
   },
   "source": [
    "# Import Libraries and Clone Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRIDt_1bVnna"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from google.colab import userdata\n",
    "from google.colab import files\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFnwhaOmZWjj",
    "outputId": "a2d00ca1-79a4-4667-a7aa-21837b225a0c"
   },
   "outputs": [],
   "source": [
    "# Import github token with google secrets thingy and clone git repository\n",
    "GITHUB_TOKEN = userdata.get('github')\n",
    "os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
    "!git clone https://{GITHUB_TOKEN}@github.com/Kussil/Financial_Sentiment_LLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hq_SPv2LyIPv"
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "CATEGORIES = [\n",
    "        \"Finance\",\n",
    "        \"Production\",\n",
    "        \"Reserves / Exploration / Acquisitions / Mergers / Divestments\",\n",
    "        \"Environment / Regulatory / Geopolitics\",\n",
    "        \"Alternative Energy / Lower Carbon\",\n",
    "        \"Oil Price / Natural Gas Price / Gasoline Price\"]\n",
    "SENTIMENT_RESULTS_FILE_PATH = '/content/Financial_Sentiment_LLM/03_Sentiment_Analysis/Prompt1_Sentiment_Analysis_Results.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzRf877uW7h0"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "QQwgVqdqXFqZ",
    "outputId": "69c42649-b225-48d0-e68a-3eccaab5d739"
   },
   "outputs": [],
   "source": [
    "# Import all cleaned data files\n",
    "invest_df1 = pd.read_csv('/content/Financial_Sentiment_LLM/02_Cleaned_Data/Investment_Research_Part1.csv')\n",
    "invest_df2 = pd.read_csv('/content/Financial_Sentiment_LLM/02_Cleaned_Data/Investment_Research_Part2.csv')\n",
    "proquest_df = pd.read_csv('/content/Financial_Sentiment_LLM/02_Cleaned_Data/ProQuest_Articles.csv')\n",
    "earnings_presentations = pd.read_csv('/content/Financial_Sentiment_LLM/02_Cleaned_Data/Earnings_Presentations.csv')\n",
    "earnings_qa = pd.read_csv('/content/Financial_Sentiment_LLM/02_Cleaned_Data/Earnings_QA.csv')\n",
    "sec_df = pd.read_csv('/content/Financial_Sentiment_LLM/02_Cleaned_Data/SEC_Filings.csv')\n",
    "\n",
    "# Merge into single df\n",
    "text_df = pd.concat([invest_df1, invest_df2, proquest_df, sec_df, earnings_presentations, earnings_qa], ignore_index=True)\n",
    "display(text_df.shape)\n",
    "display(text_df.head())\n",
    "display(text_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JuE3jrTXCPN",
    "outputId": "1e495ce3-3d12-47c2-ace6-22e62125484d"
   },
   "outputs": [],
   "source": [
    "# Drop rows google gemini will not process\n",
    "rows_to_drop = ['PQ-2840736837']\n",
    "index_to_drops = text_df[text_df['Unique_ID'].isin(rows_to_drop)].index\n",
    "text_df.drop(index_to_drops, inplace=True)\n",
    "print(index_to_drops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqZ2XDGuWNLM"
   },
   "source": [
    "# Find or Create Results CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgjxgwbZoY0b",
    "outputId": "30672a97-bd66-48b2-847d-a5dc5143c6e0"
   },
   "outputs": [],
   "source": [
    "# Determine if the Sentiment Analysis Results file already exists\n",
    "file_exists = os.path.isfile(SENTIMENT_RESULTS_FILE_PATH)\n",
    "\n",
    "# Print the result\n",
    "if file_exists:\n",
    "    print(f\"The file exists in the current directory.\")\n",
    "else:\n",
    "    print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_gsRCosWRfE"
   },
   "outputs": [],
   "source": [
    "# Create an empty file if the file does not exist\n",
    "if not file_exists:\n",
    "    # Copy text df and drop the text and headline column due to size\n",
    "    empty_sentiment_df = text_df.copy()\n",
    "    empty_sentiment_df = empty_sentiment_df.drop(['Article Text', 'Article Headline'], axis=1)\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        empty_sentiment_df[category] = \"\"\n",
    "        empty_sentiment_df[category] = empty_sentiment_df[category].astype('object')\n",
    "\n",
    "    # Display results\n",
    "    display(empty_sentiment_df.head())\n",
    "\n",
    "    # Save as CSV\n",
    "    empty_sentiment_df.to_csv(SENTIMENT_RESULTS_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WQ56LlUp-rH"
   },
   "source": [
    "### NOTE: If you want to re-run the sentiment analysis, delete or archive the csv to create a blank one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMeL1ZOcXSz9"
   },
   "source": [
    "# Sentiment Analysis\n",
    "NOTE: Google gemini **currently** has a daily query limit of 1,500 requests per day.  As we have over 10,000 documents, the code will be designed to run over multiple days and pick up where we last left off.  After the code is run, the user will still need to manually download the csv and upload to github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmpkXUk-DZfr"
   },
   "source": [
    "**Gemini Free Rate Limits**\n",
    "*   15 RPM (requests per minute)\n",
    "*   1 million TPM (tokens per minute)\n",
    "*   1,500 RPD (requests per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVdZDCVf2iHr"
   },
   "outputs": [],
   "source": [
    "# Set up Gemini. (API Key needs to be in your secrets)\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# So it doesn't block the output\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",},]\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22Zt879CulED",
    "outputId": "bf2bb06a-32ab-41d9-b030-4e2fcb412fca"
   },
   "outputs": [],
   "source": [
    "# Function to find the first empty row of the csv\n",
    "def find_first_unique_id_with_empty_values(file_path, categories):\n",
    "    \"\"\"\n",
    "    Finds the first unique ID where any of the specified columns have empty values in a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        categories (list of str): List of column names to check for empty values.\n",
    "\n",
    "    Returns:\n",
    "        str: The first Unique_ID where any of the specified columns have empty values.\n",
    "        None: If no such row is found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Iterate over each row to find the first unique ID with any empty values in the specified columns\n",
    "    for index, row in df.iterrows():\n",
    "        if row[categories].isnull().any() or (row[categories] == '').any():\n",
    "            return row['Unique_ID']\n",
    "\n",
    "    return None  # Return None if no such row is found\n",
    "\n",
    "# Test function\n",
    "unique_id = find_first_unique_id_with_empty_values(SENTIMENT_RESULTS_FILE_PATH, CATEGORIES)\n",
    "print(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0Gg79X82NYq",
    "outputId": "31fcd9ed-efd3-4f90-fbf5-c2ddc87cdf15"
   },
   "outputs": [],
   "source": [
    "# Helper function to get Gemini query function inputs\n",
    "def get_gemini_inputs(text_df, unique_id):\n",
    "    \"\"\"\n",
    "    Retrieves information from the DataFrame based on the unique ID and outputs company, source, headline, and text.\n",
    "\n",
    "    Args:\n",
    "        text_df (pd.DataFrame): The DataFrame containing the text data.\n",
    "        unique_id (str): The unique ID to search for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing company, source, headline, and text.\n",
    "    \"\"\"\n",
    "    # Find the row with the specified unique ID\n",
    "    row = text_df[text_df['Unique_ID'] == unique_id]\n",
    "\n",
    "    # Extract the required information\n",
    "    company = row['Ticker'].values[0]\n",
    "    source = row['Source'].values[0]\n",
    "    headline = row['Article Headline'].values[0]\n",
    "    text = row['Article Text'].values[0]\n",
    "\n",
    "    return company, source, headline, text\n",
    "\n",
    "# Test function\n",
    "company, source, headline, text = get_gemini_inputs(text_df, unique_id)\n",
    "print(f\"Company: {company}\\n\")\n",
    "print(f\"Source: {source}\\n\")\n",
    "print(f\"Headline: {headline}\\n\")\n",
    "print(f\"Text:\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "eRjhvk_9Xapi",
    "outputId": "af5aecce-a180-4e54-ed6d-cbba95700ec6"
   },
   "outputs": [],
   "source": [
    "# Function to query Gemini\n",
    "def query_gemini(company, source, headline, text, model):\n",
    "    \"\"\"\n",
    "    Query Gemini to perform sentiment analysis on text from various sources about a company.\n",
    "\n",
    "    Parameters:\n",
    "    company (str): The name of the company the text is about.\n",
    "    source (str): The source of the text. Valid values are \"Investment Research\", \"ProQuest\", \"SEC Filings\", \"Earnings Call Presentations\", \"Earnings Call Q&A\".\n",
    "    headline (str): The headline or title of the text.\n",
    "    text (str): The body of the text to be analyzed.\n",
    "    model: The model object used to generate content and analyze the text.\n",
    "\n",
    "    Returns:\n",
    "    str: The sentiment analysis results for predefined categories in the specified format.\n",
    "\n",
    "    The function constructs a prompt based on the source of the text and performs sentiment analysis on the given text using the provided model.\n",
    "    It analyzes the content across multiple predefined categories, determining the sentiment (Positive, Neutral, Negative) for each category.\n",
    "    If a category is not mentioned or relevant based on the text content, it is marked as 'Neutral'.\n",
    "    The final output is summarized in a specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Source Variables\n",
    "    if source == \"Investment Research\":\n",
    "        text_source = \"an analyst report\"\n",
    "        text_source2 = \"the analyst report\"\n",
    "    elif source == \"ProQuest\":\n",
    "        text_source = \"a news article\"\n",
    "        text_source2 = \"the news article\"\n",
    "    elif source == \"SEC Filings\":\n",
    "        text_source = \"an SEC filing\"\n",
    "        text_source2 = \"the SEC filing\"\n",
    "    elif source == \"Earnings Call Presentations\":\n",
    "        text_source = \"an earnings call presentation\"\n",
    "        text_source2 = \"the earnings call presentation\"\n",
    "    elif source == \"Earnings Call Q&A\":\n",
    "        text_source = \"an earnings call Q&A session\"\n",
    "        text_source2 = \"the earnings call Q&A session\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt = f\"\"\"\n",
    "Given the text from {text_source} about {company}, analyze the content and perform sentiment analysis across multiple predefined categories.\n",
    "\n",
    "Sentiment options:\n",
    "  - Positive\n",
    "  - Neutral\n",
    "  - Negative\n",
    "\n",
    "Categories:\n",
    "  - Finance\n",
    "  - Production\n",
    "  - Reserves / Exploration / Acquisitions / Mergers / Divestments\n",
    "  - Environment / Regulatory / Geopolitics\n",
    "  - Alternative Energy / Lower Carbon\n",
    "  - Oil Price / Natural Gas Price / Gasoline Price\n",
    "\n",
    "Each category should be evaluated and given a sentiment output derived from the text.\n",
    "If a category is not mentioned or relevant based on the text content, mark it as 'Neutral'.\n",
    "\n",
    "Before giving your answer, explain your reasoning and reference the article.\n",
    "After going through all the categories, provide a summary in the following format:\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "\n",
    "Example Output1:\n",
    "- Finance - Positive\n",
    "- Production - Neutral\n",
    "- Reserves / Exploration / Acquisitions / Mergers / Divestments - Negative\n",
    "- Environment / Regulatory / Geopolitics - Neutral\n",
    "- Alternative Energy / Lower Carbon - Positive\n",
    "- Oil Price / Natural Gas Price / Gasoline Price - Neutral\n",
    "\n",
    "Example Output 2:\n",
    " - Finance - Negative\n",
    " - Production - Positive\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Neutral\n",
    " - Environment / Regulatory / Geopolitics - Positive\n",
    " - Alternative Energy / Lower Carbon - Neutral\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Negative\n",
    "\n",
    "Example Output 3:\n",
    " - Finance - Neutral\n",
    " - Production - Negative\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Positive\n",
    " - Environment / Regulatory / Geopolitics - Negative\n",
    " - Alternative Energy / Lower Carbon - Positive\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Neutral\n",
    "\n",
    "Example Output 4:\n",
    " - Finance - Positive\n",
    " - Production - Neutral\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Negative\n",
    " - Environment / Regulatory / Geopolitics - Neutral\n",
    " - Alternative Energy / Lower Carbon - Negative\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Positive\n",
    "\n",
    "Example Output 5:\n",
    " - Finance - Negative\n",
    " - Production - Positive\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Neutral\n",
    " - Environment / Regulatory / Geopolitics - Negative\n",
    " - Alternative Energy / Lower Carbon - Positive\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Negative\n",
    "\n",
    "Make sure to use plain text, do not bold or bullet the output summary.\n",
    "\n",
    "The text from {text_source2} is below:\n",
    "{headline}\n",
    "{text}\n",
    "\n",
    "Remember to summarize your final answers in the following format exactly:\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "\n",
    "Make sure to use plain text and stick to the given categories and sentiment options.\n",
    "DO NOT bold or bullet the output summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # print(prompt)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Test function\n",
    "response = query_gemini(company, source, headline, text, model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbTgA_znnYIX",
    "outputId": "54e2646a-c518-4480-fb32-0d2266f3e8a4"
   },
   "outputs": [],
   "source": [
    "# Function to parse text\n",
    "def parse_sentiment(text, categories):\n",
    "    \"\"\"\n",
    "    Parses a given text for specified categories and their sentiments.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing categories and their sentiments.\n",
    "        categories (list of str): List of category names to look for in the text.\n",
    "\n",
    "    Returns:\n",
    "        dict or str: A dictionary with categories as keys and their corresponding sentiments as values,\n",
    "                     or \"Did not find all categories\" if any sentiment is not Positive, Neutral, or Negative.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    valid_sentiments = {\"Positive\", \"Neutral\", \"Negative\"}\n",
    "\n",
    "    for category in categories:\n",
    "        # Create a regex pattern to match the format \"- Category - Sentiment\"\n",
    "        # The category name is escaped to handle any special characters\n",
    "        pattern = rf\"- {re.escape(category)} - (\\w+)\"\n",
    "\n",
    "        # Search for the pattern in the text\n",
    "        match = re.search(pattern, text)\n",
    "\n",
    "        # If a match is found, extract the sentiment and add it to the results dictionary\n",
    "        if match:\n",
    "            sentiment = match.group(1)\n",
    "            if sentiment not in valid_sentiments:\n",
    "                return \"Did not find all categories\"\n",
    "            results[category] = sentiment\n",
    "        else:\n",
    "            return \"Did not find all categories\"\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test function\n",
    "fail_text = \"\"\"\n",
    "- Finance - Positive\n",
    "- Production - Neutral\n",
    "- Reserves / Exploration / Acquisitions / Mergers / Divestments - Bad\n",
    "- Environment / Regulatory / Geopolitics - Neutral\n",
    "- Alternative Energy / Lower Carbon - Positive\n",
    "- Oil Price / Natural Gas Price / Gasoline Price - Neutral\n",
    "\"\"\"\n",
    "\n",
    "sentiment_dict = parse_sentiment(response, CATEGORIES)\n",
    "fail_sentiment = parse_sentiment(\"fail_text\", CATEGORIES)\n",
    "print(sentiment_dict)\n",
    "print(fail_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfIujTIrXj18",
    "outputId": "3c5dce31-40a8-48f6-8248-1d71917bd7cb"
   },
   "outputs": [],
   "source": [
    "# Function to update the csv\n",
    "def update_csv(file_path, unique_id, sentiment_dict):\n",
    "    \"\"\"\n",
    "    Updates the columns of a CSV file based on the unique ID and sentiment dictionary.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        unique_id (str): The unique ID of the row to be updated.\n",
    "        sentiment_dict (dict): A dictionary with categories as keys and their corresponding sentiments as values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Find the index of the row with the specified unique ID\n",
    "    row_index = df[df['Unique_ID'] == unique_id].index\n",
    "\n",
    "    # Update the columns based on the sentiment dictionary\n",
    "    for category, sentiment in sentiment_dict.items():\n",
    "        df.loc[row_index, category] = sentiment\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Row with Unique_ID '{unique_id}' has been updated.\")\n",
    "\n",
    "# Test function\n",
    "update_csv(SENTIMENT_RESULTS_FILE_PATH, unique_id, sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ANJgrUqEr1tE",
    "outputId": "1167440a-adfc-4a43-d586-d5b5076cebdf"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "unique_id = find_first_unique_id_with_empty_values(SENTIMENT_RESULTS_FILE_PATH, CATEGORIES)\n",
    "count = 0\n",
    "max_tries = 5\n",
    "\n",
    "# Iterate through the CSV using the functions\n",
    "while unique_id:\n",
    "    retries = 0\n",
    "    success = False\n",
    "\n",
    "    # There are multiple errors that can happen, many of them simply need another try\n",
    "    while retries < max_tries and not success:\n",
    "        try:\n",
    "            # Get gemini inputs\n",
    "            company, source, headline, text = get_gemini_inputs(text_df, unique_id)\n",
    "\n",
    "            # Query Gemini\n",
    "            response = query_gemini(company, source, headline, text, model)\n",
    "\n",
    "            # Parse text\n",
    "            sentiment_dict = parse_sentiment(response, CATEGORIES)\n",
    "\n",
    "            # Update the csv\n",
    "            update_csv(SENTIMENT_RESULTS_FILE_PATH, unique_id, sentiment_dict)\n",
    "\n",
    "            success = True\n",
    "\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Error encountered: {e}. Retry {retries}/{max_tries}\")\n",
    "\n",
    "            if retries >= max_tries:\n",
    "                print(f\"Failed to process unique_id {unique_id} after {max_tries} attempts. Stopping.\")\n",
    "                # Exit both loops\n",
    "                unique_id = None\n",
    "                break\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Get an update every 10 rows\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "        print(f\"Iteration: {count}, Elapsed Time: {int(minutes)} minutes and {seconds:.2f} seconds\")\n",
    "\n",
    "    # Find the next empty row\n",
    "    unique_id = find_first_unique_id_with_empty_values(SENTIMENT_RESULTS_FILE_PATH, CATEGORIES)\n",
    "\n",
    "    # Test print statements\n",
    "    # print(unique_id)\n",
    "    # print(f\"Company: {company}\\n\")\n",
    "    # print(f\"Source: {source}\\n\")\n",
    "    # print(f\"Headline: {headline}\\n\")\n",
    "    # print(f\"Text:\\n{text}\")\n",
    "    # print(response)\n",
    "    # print(sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "i5ATLg2LhxzY",
    "outputId": "9f03835f-cec0-4236-a253-5f519b7df00e"
   },
   "outputs": [],
   "source": [
    "# Download file when done so you don't lose it\n",
    "from google.colab import files\n",
    "files.download(SENTIMENT_RESULTS_FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
