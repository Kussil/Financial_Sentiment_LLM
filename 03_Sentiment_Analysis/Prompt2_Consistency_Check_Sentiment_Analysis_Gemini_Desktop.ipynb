{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy9ROy-SV-U8"
   },
   "source": [
    "# Import Libraries and Clone Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pRIDt_1bVnna"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hq_SPv2LyIPv"
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "CATEGORIES = [\n",
    "        \"Finance\",\n",
    "        \"Production\",\n",
    "        \"Reserves / Exploration / Acquisitions / Mergers / Divestments\",\n",
    "        \"Environment / Regulatory / Geopolitics\",\n",
    "        \"Alternative Energy / Lower Carbon\",\n",
    "        \"Oil Price / Natural Gas Price / Gasoline Price\"]\n",
    "SENTIMENT_RESULTS_FILE_PATH = 'Prompt2_Consistency_Check_Sentiment_Analysis_Results.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzRf877uW7h0"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "QQwgVqdqXFqZ",
    "outputId": "8d908241-04e1-4f45-e407-699f50d1f94b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10053, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article Headline</th>\n",
       "      <th>Article Text</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-1</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2024-05-16</td>\n",
       "      <td>Marathon Oil Corporation</td>\n",
       "      <td>Stock Report | May 16, 2024 | NYSESymbol: MRO ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-2</td>\n",
       "      <td>EOG</td>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>Stock Report | May 14, 2024 | NYSESymbol: EOG ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3</td>\n",
       "      <td>EOG</td>\n",
       "      <td>2024-05-11</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>Stock Report | May 11, 2024 | NYSESymbol: EOG ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-4</td>\n",
       "      <td>DVN</td>\n",
       "      <td>2024-05-11</td>\n",
       "      <td>Devon Energy Corporation</td>\n",
       "      <td>Stock Report | May 11, 2024 | NYSESymbol: DVN ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-5</td>\n",
       "      <td>COP</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>ConocoPhillips</td>\n",
       "      <td>Stock Report | May 07, 2024 | NYSESymbol: COP ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Source Unique_ID Ticker        Date          Article Headline  \\\n",
       "0  Investment Research      IR-1    MRO  2024-05-16  Marathon Oil Corporation   \n",
       "1  Investment Research      IR-2    EOG  2024-05-14       EOG Resources, Inc.   \n",
       "2  Investment Research      IR-3    EOG  2024-05-11       EOG Resources, Inc.   \n",
       "3  Investment Research      IR-4    DVN  2024-05-11  Devon Energy Corporation   \n",
       "4  Investment Research      IR-5    COP  2024-05-07            ConocoPhillips   \n",
       "\n",
       "                                        Article Text  URL  \n",
       "0  Stock Report | May 16, 2024 | NYSESymbol: MRO ...  NaN  \n",
       "1  Stock Report | May 14, 2024 | NYSESymbol: EOG ...  NaN  \n",
       "2  Stock Report | May 11, 2024 | NYSESymbol: EOG ...  NaN  \n",
       "3  Stock Report | May 11, 2024 | NYSESymbol: DVN ...  NaN  \n",
       "4  Stock Report | May 07, 2024 | NYSESymbol: COP ...  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article Headline</th>\n",
       "      <th>Article Text</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10048</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-338</td>\n",
       "      <td>XOM</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>Exxon Mobil Corporation, Q4 2020 Earnings Call...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10049</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-339</td>\n",
       "      <td>COP</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>ConocoPhillips, Q4 2020 Earnings Call, Feb 02,...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10050</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-340</td>\n",
       "      <td>EOG</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>EOG Resources, Inc., Q1 2019 Earnings Call, Ma...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-341</td>\n",
       "      <td>SHEL</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>Royal Dutch Shell plc, Q1 2019 Earnings Call, ...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10052</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-342</td>\n",
       "      <td>COP</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>ConocoPhillips, Q1 2019 Earnings Call, Apr 30,...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Source Unique_ID Ticker        Date  \\\n",
       "10048  Earnings Call Q&A    EQ-338    XOM  2021-02-02   \n",
       "10049  Earnings Call Q&A    EQ-339    COP  2021-02-02   \n",
       "10050  Earnings Call Q&A    EQ-340    EOG  2019-05-03   \n",
       "10051  Earnings Call Q&A    EQ-341   SHEL  2019-05-02   \n",
       "10052  Earnings Call Q&A    EQ-342    COP  2019-04-30   \n",
       "\n",
       "                                        Article Headline  \\\n",
       "10048  Exxon Mobil Corporation, Q4 2020 Earnings Call...   \n",
       "10049  ConocoPhillips, Q4 2020 Earnings Call, Feb 02,...   \n",
       "10050  EOG Resources, Inc., Q1 2019 Earnings Call, Ma...   \n",
       "10051  Royal Dutch Shell plc, Q1 2019 Earnings Call, ...   \n",
       "10052  ConocoPhillips, Q1 2019 Earnings Call, Apr 30,...   \n",
       "\n",
       "                                            Article Text  URL  \n",
       "10048  Question and Answer\\nOperator\\n[Operator Instr...  NaN  \n",
       "10049  Question and Answer\\nOperator\\n[Operator Instr...  NaN  \n",
       "10050  Question and Answer\\nOperator\\n[Operator Instr...  NaN  \n",
       "10051  Question and Answer\\nOperator\\n[Operator Instr...  NaN  \n",
       "10052  Question and Answer\\nOperator\\n[Operator Instr...  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import all cleaned data files\n",
    "invest_df1 = pd.read_csv('../02_Cleaned_Data/Investment_Research_Part1.csv')\n",
    "invest_df2 = pd.read_csv('../02_Cleaned_Data/Investment_Research_Part2.csv')\n",
    "proquest_df = pd.read_csv('../02_Cleaned_Data/ProQuest_Articles.csv')\n",
    "earnings_presentations = pd.read_csv('../02_Cleaned_Data/Earnings_Presentations.csv')\n",
    "earnings_qa = pd.read_csv('../02_Cleaned_Data/Earnings_QA.csv')\n",
    "sec_df = pd.read_csv('../02_Cleaned_Data/SEC_Filings.csv')\n",
    "\n",
    "# Merge into single df\n",
    "text_df = pd.concat([invest_df1, invest_df2, proquest_df, sec_df, earnings_presentations, earnings_qa], ignore_index=True)\n",
    "display(text_df.shape)\n",
    "display(text_df.head())\n",
    "display(text_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([5379], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Drop rows google gemini will not process\n",
    "rows_to_drop = ['PQ-2840736837']\n",
    "index_to_drops = text_df[text_df['Unique_ID'].isin(rows_to_drop)].index\n",
    "text_df.drop(index_to_drops, inplace=True)\n",
    "print(index_to_drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article Headline</th>\n",
       "      <th>Article Text</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3734</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | November 13, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-726</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>Marathon Oil Corporation</td>\n",
       "      <td>Stock Report | May 21, 2022 | NYSE Symbol: MRO...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-299</td>\n",
       "      <td>MRO</td>\n",
       "      <td>2023-06-24</td>\n",
       "      <td>Marathon Oil Corporation</td>\n",
       "      <td>Stock Report | June 24, 2023 | NYSE Symbol: MR...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-2095</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>Chevron Corporation</td>\n",
       "      <td>Stock Report | November 20, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-4168</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | February 20, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ProQuest</td>\n",
       "      <td>PQ-2540764382</td>\n",
       "      <td>XOM</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>Exxon Stock Could Rise 40 With Big Dividend</td>\n",
       "      <td>For most of the past year and a half, the big ...</td>\n",
       "      <td>https://www.proquest.com/newspapers/exxon-stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ProQuest</td>\n",
       "      <td>PQ-2415718613</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>Banking &amp; Finance: Chevron Saudi-Kuwait Projec...</td>\n",
       "      <td>Big oil companies returned to profitability du...</td>\n",
       "      <td>https://www.proquest.com/newspapers/exchange-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ProQuest</td>\n",
       "      <td>PQ-2641736904</td>\n",
       "      <td>XOM</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>So Much Climate Activism At Exxon Mobil</td>\n",
       "      <td>Many readers may have been surprised to see Ch...</td>\n",
       "      <td>https://www.proquest.com/newspapers/so-much-cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ProQuest</td>\n",
       "      <td>PQ-2880296882</td>\n",
       "      <td>OXY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Occidental Petroleum Stock Falls. It Lost a Po...</td>\n",
       "      <td>Occidental Petroleum shares had the worst show...</td>\n",
       "      <td>https://www.proquest.com/newspapers/occidental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ProQuest</td>\n",
       "      <td>PQ-2857037564</td>\n",
       "      <td>EQNR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Norway: Speech by the Prime Minister at the op...</td>\n",
       "      <td>By Prime Minister Jonas Gahr StøreYour Royal H...</td>\n",
       "      <td>https://www.proquest.com/newspapers/norway-spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SEC Filings</td>\n",
       "      <td>SEC-110465920132038</td>\n",
       "      <td>COP</td>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>8-K</td>\n",
       "      <td>\\n0001163165\\nfalse\\n0001163165\\n2020-11-30\\n2...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEC Filings</td>\n",
       "      <td>SEC-9341020000015</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>8-K</td>\n",
       "      <td>\\nfalse0000093410\\n0000093410\\n2020-05-01\\n202...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SEC Filings</td>\n",
       "      <td>SEC-9341021000031</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0000093410false00000934102021-07-272021-07-27U...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SEC Filings</td>\n",
       "      <td>SEC-9341019000008</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>10-K</td>\n",
       "      <td>\\nUNITED STATES SECURITIES AND EXCHANGE COMMIS...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SEC Filings</td>\n",
       "      <td>SEC-119312519084325</td>\n",
       "      <td>XOM</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>8-K</td>\n",
       "      <td>\\nUNITED STATES \\nSECURITIES AND EXCHANGE COMM...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Earnings Call Presentations</td>\n",
       "      <td>EP-210</td>\n",
       "      <td>SHEL</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>Royal Dutch Shell plc, Q3 2021 Earnings Call, ...</td>\n",
       "      <td>Royal Dutch Shell plc ENXTAM:RDSA\\nFQ3 2021 Ea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Earnings Call Presentations</td>\n",
       "      <td>EP-257</td>\n",
       "      <td>BP</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>BP p.l.c., Q3 2022 Earnings Call, Nov 01, 2022</td>\n",
       "      <td>BP p.l.c. LSE:BP.\\nFQ3 2022 Earnings Call Tran...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Earnings Call Presentations</td>\n",
       "      <td>EP-98</td>\n",
       "      <td>DVN</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>Devon Energy Corporation, Q4 2020 Earnings Cal...</td>\n",
       "      <td>Devon Energy Corporation NYSE:DVN\\nFQ4 2020 Ea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Earnings Call Presentations</td>\n",
       "      <td>EP-33</td>\n",
       "      <td>VLO</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>Valero Energy Corporation, Q1 2019 Earnings Ca...</td>\n",
       "      <td>Valero Energy Corporation NYSE:VLO\\nFQ1 2019 E...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Earnings Call Presentations</td>\n",
       "      <td>EP-10</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>Chevron Corporation, Q4 2021 Earnings Call, Ja...</td>\n",
       "      <td>Chevron Corporation NYSE:CVX\\nFQ4 2021 Earning...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-167</td>\n",
       "      <td>VLO</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>Valero Energy Corporation, Q1 2023 Earnings Ca...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-7</td>\n",
       "      <td>CVX</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>Chevron Corporation, Q3 2022 Earnings Call, Oc...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-115</td>\n",
       "      <td>OXY</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>Occidental Petroleum Corporation, Q2 2021 Earn...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-72</td>\n",
       "      <td>DVN</td>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>Devon Energy Corporation, Q1 2020 Earnings Cal...</td>\n",
       "      <td>Question and Answer\\nOperator\\nYour first ques...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Earnings Call Q&amp;A</td>\n",
       "      <td>EQ-132</td>\n",
       "      <td>OXY</td>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Occidental Petroleum Corporation, Q4 2021 Earn...</td>\n",
       "      <td>Question and Answer\\nOperator\\n[Operator Instr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Source            Unique_ID Ticker        Date  \\\n",
       "0           Investment Research              IR-3734    HES  2021-11-13   \n",
       "1           Investment Research               IR-726    MRO  2022-05-21   \n",
       "2           Investment Research               IR-299    MRO  2023-06-24   \n",
       "3           Investment Research              IR-2095    CVX  2021-11-21   \n",
       "4           Investment Research              IR-4168    HES  2021-02-20   \n",
       "5                      ProQuest        PQ-2540764382    XOM  2021-06-15   \n",
       "6                      ProQuest        PQ-2415718613    CVX  2020-06-23   \n",
       "7                      ProQuest        PQ-2641736904    XOM  2022-03-23   \n",
       "8                      ProQuest        PQ-2880296882    OXY         NaN   \n",
       "9                      ProQuest        PQ-2857037564   EQNR         NaN   \n",
       "10                  SEC Filings  SEC-110465920132038    COP  2020-12-03   \n",
       "11                  SEC Filings    SEC-9341020000015    CVX  2020-05-01   \n",
       "12                  SEC Filings    SEC-9341021000031    CVX  2021-08-02   \n",
       "13                  SEC Filings    SEC-9341019000008    CVX  2019-02-22   \n",
       "14                  SEC Filings  SEC-119312519084325    XOM  2019-03-25   \n",
       "15  Earnings Call Presentations               EP-210   SHEL  2021-10-28   \n",
       "16  Earnings Call Presentations               EP-257     BP  2022-11-01   \n",
       "17  Earnings Call Presentations                EP-98    DVN  2021-02-17   \n",
       "18  Earnings Call Presentations                EP-33    VLO  2019-04-25   \n",
       "19  Earnings Call Presentations                EP-10    CVX  2022-01-28   \n",
       "20            Earnings Call Q&A               EQ-167    VLO  2023-04-27   \n",
       "21            Earnings Call Q&A                 EQ-7    CVX  2022-10-28   \n",
       "22            Earnings Call Q&A               EQ-115    OXY  2021-08-04   \n",
       "23            Earnings Call Q&A                EQ-72    DVN  2020-05-06   \n",
       "24            Earnings Call Q&A               EQ-132    OXY  2022-02-25   \n",
       "\n",
       "                                     Article Headline  \\\n",
       "0                                    Hess Corporation   \n",
       "1                            Marathon Oil Corporation   \n",
       "2                            Marathon Oil Corporation   \n",
       "3                                 Chevron Corporation   \n",
       "4                                    Hess Corporation   \n",
       "5         Exxon Stock Could Rise 40 With Big Dividend   \n",
       "6   Banking & Finance: Chevron Saudi-Kuwait Projec...   \n",
       "7             So Much Climate Activism At Exxon Mobil   \n",
       "8   Occidental Petroleum Stock Falls. It Lost a Po...   \n",
       "9   Norway: Speech by the Prime Minister at the op...   \n",
       "10                                                8-K   \n",
       "11                                                8-K   \n",
       "12                                                8-K   \n",
       "13                                               10-K   \n",
       "14                                                8-K   \n",
       "15  Royal Dutch Shell plc, Q3 2021 Earnings Call, ...   \n",
       "16     BP p.l.c., Q3 2022 Earnings Call, Nov 01, 2022   \n",
       "17  Devon Energy Corporation, Q4 2020 Earnings Cal...   \n",
       "18  Valero Energy Corporation, Q1 2019 Earnings Ca...   \n",
       "19  Chevron Corporation, Q4 2021 Earnings Call, Ja...   \n",
       "20  Valero Energy Corporation, Q1 2023 Earnings Ca...   \n",
       "21  Chevron Corporation, Q3 2022 Earnings Call, Oc...   \n",
       "22  Occidental Petroleum Corporation, Q2 2021 Earn...   \n",
       "23  Devon Energy Corporation, Q1 2020 Earnings Cal...   \n",
       "24  Occidental Petroleum Corporation, Q4 2021 Earn...   \n",
       "\n",
       "                                         Article Text  \\\n",
       "0   Stock Report | November 13, 2021 | NYSE Symbol...   \n",
       "1   Stock Report | May 21, 2022 | NYSE Symbol: MRO...   \n",
       "2   Stock Report | June 24, 2023 | NYSE Symbol: MR...   \n",
       "3   Stock Report | November 20, 2021 | NYSE Symbol...   \n",
       "4   Stock Report | February 20, 2021 | NYSE Symbol...   \n",
       "5   For most of the past year and a half, the big ...   \n",
       "6   Big oil companies returned to profitability du...   \n",
       "7   Many readers may have been surprised to see Ch...   \n",
       "8   Occidental Petroleum shares had the worst show...   \n",
       "9   By Prime Minister Jonas Gahr StøreYour Royal H...   \n",
       "10  \\n0001163165\\nfalse\\n0001163165\\n2020-11-30\\n2...   \n",
       "11  \\nfalse0000093410\\n0000093410\\n2020-05-01\\n202...   \n",
       "12  0000093410false00000934102021-07-272021-07-27U...   \n",
       "13  \\nUNITED STATES SECURITIES AND EXCHANGE COMMIS...   \n",
       "14  \\nUNITED STATES \\nSECURITIES AND EXCHANGE COMM...   \n",
       "15  Royal Dutch Shell plc ENXTAM:RDSA\\nFQ3 2021 Ea...   \n",
       "16  BP p.l.c. LSE:BP.\\nFQ3 2022 Earnings Call Tran...   \n",
       "17  Devon Energy Corporation NYSE:DVN\\nFQ4 2020 Ea...   \n",
       "18  Valero Energy Corporation NYSE:VLO\\nFQ1 2019 E...   \n",
       "19  Chevron Corporation NYSE:CVX\\nFQ4 2021 Earning...   \n",
       "20  Question and Answer\\nOperator\\n[Operator Instr...   \n",
       "21  Question and Answer\\nOperator\\n[Operator Instr...   \n",
       "22  Question and Answer\\nOperator\\n[Operator Instr...   \n",
       "23  Question and Answer\\nOperator\\nYour first ques...   \n",
       "24  Question and Answer\\nOperator\\n[Operator Instr...   \n",
       "\n",
       "                                                  URL  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5   https://www.proquest.com/newspapers/exxon-stoc...  \n",
       "6   https://www.proquest.com/newspapers/exchange-b...  \n",
       "7   https://www.proquest.com/newspapers/so-much-cl...  \n",
       "8   https://www.proquest.com/newspapers/occidental...  \n",
       "9   https://www.proquest.com/newspapers/norway-spe...  \n",
       "10  https://www.sec.gov/Archives/edgar/data/000116...  \n",
       "11  https://www.sec.gov/Archives/edgar/data/000009...  \n",
       "12  https://www.sec.gov/Archives/edgar/data/000009...  \n",
       "13  https://www.sec.gov/Archives/edgar/data/000009...  \n",
       "14  https://www.sec.gov/Archives/edgar/data/000003...  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample 5 random articles from each source\n",
    "# Identify the unique sources\n",
    "unique_sources = text_df['Source'].unique()\n",
    "sampled_df = pd.DataFrame()\n",
    "\n",
    "# Sample 5 random rows from each source\n",
    "for source in unique_sources:\n",
    "    source_df = text_df[text_df['Source'] == source]\n",
    "    sampled_rows = source_df.sample(n=5, random_state=42)\n",
    "    sampled_df = pd.concat([sampled_df, sampled_rows], ignore_index=True)\n",
    "\n",
    "display(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article Headline</th>\n",
       "      <th>Article Text</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3734 1</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | November 13, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3734 2</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | November 13, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3734 3</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | November 13, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3734 4</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | November 13, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Investment Research</td>\n",
       "      <td>IR-3734 5</td>\n",
       "      <td>HES</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>Hess Corporation</td>\n",
       "      <td>Stock Report | November 13, 2021 | NYSE Symbol...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Source  Unique_ID Ticker        Date  Article Headline  \\\n",
       "0  Investment Research  IR-3734 1    HES  2021-11-13  Hess Corporation   \n",
       "1  Investment Research  IR-3734 2    HES  2021-11-13  Hess Corporation   \n",
       "2  Investment Research  IR-3734 3    HES  2021-11-13  Hess Corporation   \n",
       "3  Investment Research  IR-3734 4    HES  2021-11-13  Hess Corporation   \n",
       "4  Investment Research  IR-3734 5    HES  2021-11-13  Hess Corporation   \n",
       "\n",
       "                                        Article Text  URL  \n",
       "0  Stock Report | November 13, 2021 | NYSE Symbol...  NaN  \n",
       "1  Stock Report | November 13, 2021 | NYSE Symbol...  NaN  \n",
       "2  Stock Report | November 13, 2021 | NYSE Symbol...  NaN  \n",
       "3  Stock Report | November 13, 2021 | NYSE Symbol...  NaN  \n",
       "4  Stock Report | November 13, 2021 | NYSE Symbol...  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 7)\n"
     ]
    }
   ],
   "source": [
    "# Duplicate each row 10 times\n",
    "repeated_df = sampled_df.loc[sampled_df.index.repeat(10)].reset_index(drop=True)\n",
    "\n",
    "# Update the Unique_ID column\n",
    "repeated_df['Unique_ID'] = repeated_df['Unique_ID'] + ' ' + repeated_df.groupby(repeated_df.index // 10).cumcount().add(1).astype(str)\n",
    "display(repeated_df.head())\n",
    "print(repeated_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqZ2XDGuWNLM"
   },
   "source": [
    "# Find or Create Results CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgjxgwbZoY0b",
    "outputId": "bda7c259-5480-483f-d674-016402ddf9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists in the current directory.\n"
     ]
    }
   ],
   "source": [
    "# Determine if the Sentiment Analysis Results file already exists\n",
    "file_exists = os.path.isfile(SENTIMENT_RESULTS_FILE_PATH)\n",
    "\n",
    "# Print the result\n",
    "if file_exists:\n",
    "    print(f\"The file exists in the current directory.\")\n",
    "else:\n",
    "    print(f\"The file does not exist in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3_gsRCosWRfE"
   },
   "outputs": [],
   "source": [
    "# Create an empty file if the file does not exist\n",
    "if not file_exists:\n",
    "    # Copy repeated df and drop the text and headline column due to size\n",
    "    empty_sentiment_df = repeated_df.copy()\n",
    "    empty_sentiment_df = empty_sentiment_df.drop(['Article Text', 'Article Headline'], axis=1)\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        empty_sentiment_df[category] = \"\"\n",
    "        empty_sentiment_df[category] = empty_sentiment_df[category].astype('object')\n",
    "\n",
    "    # Display results\n",
    "    display(empty_sentiment_df.head())\n",
    "\n",
    "    # Save as CSV\n",
    "    empty_sentiment_df.to_csv(SENTIMENT_RESULTS_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WQ56LlUp-rH"
   },
   "source": [
    "### NOTE: If you want to re-run the sentiment analysis, delete or archive the csv to create a blank one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMeL1ZOcXSz9"
   },
   "source": [
    "# Sentiment Analysis\n",
    "NOTE: Google gemini **currently** has a daily query limit of 1,500 requests per day.  As we have over 10,000 documents, the code will be designed to run over multiple days and pick up where we last left off.  After the code is run, the user will still need to manually download the csv and upload to github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmpkXUk-DZfr"
   },
   "source": [
    "**Gemini Free Rate Limits**\n",
    "*   15 RPM (requests per minute)\n",
    "*   1 million TPM (tokens per minute)\n",
    "*   1,500 RPD (requests per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nVdZDCVf2iHr"
   },
   "outputs": [],
   "source": [
    "# Set up Gemini. (API key needs to be in your environment variables)\n",
    "key = 'GOOGLE_API_KEY'\n",
    "GOOGLE_API_KEY = os.getenv(key)\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# So it doesn't block the output\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",},]\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-latest', safety_settings=safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22Zt879CulED",
    "outputId": "59e59419-e4a3-4ea9-a151-5d84a8799f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP-210 7\n"
     ]
    }
   ],
   "source": [
    "# Function to find the first empty row of the csv\n",
    "def find_first_unique_id_with_empty_values(file_path, categories):\n",
    "    \"\"\"\n",
    "    Finds the first unique ID where any of the specified columns have empty values in a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        categories (list of str): List of column names to check for empty values.\n",
    "\n",
    "    Returns:\n",
    "        str: The first Unique_ID where any of the specified columns have empty values.\n",
    "        None: If no such row is found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Iterate over each row to find the first unique ID with any empty values in the specified columns\n",
    "    for index, row in df.iterrows():\n",
    "        if row[categories].isnull().any() or (row[categories] == '').any():\n",
    "            return row['Unique_ID']\n",
    "\n",
    "    return None  # Return None if no such row is found\n",
    "\n",
    "# Test function\n",
    "unique_id = find_first_unique_id_with_empty_values(SENTIMENT_RESULTS_FILE_PATH, CATEGORIES)\n",
    "print(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0Gg79X82NYq",
    "outputId": "dd6b7aa5-40c0-4155-bc76-d647f9b9d8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: SHEL\n",
      "\n",
      "Source: Earnings Call Presentations\n",
      "\n",
      "Headline: Royal Dutch Shell plc, Q3 2021 Earnings Call, Oct 28, 2021\n",
      "\n",
      "Text:\n",
      "Royal Dutch Shell plc ENXTAM:RDSA\n",
      "FQ3 2021 Earnings Call Transcripts\n",
      "Thursday, October 28, 2021 1:00 PM GMT\n",
      "S&P Global Market Intelligence Estimates\n",
      "-FQ3 2021- -FQ4 2021- -FY 2021- -FY 2022-\n",
      "CONSENSUS ACTUAL SURPRISE CONSENSUS CONSENSUS CONSENSUS\n",
      "EPS Normalized 0.70 0.53 (24.29 %) 0.92 2.45 3.02\n",
      "Revenue (mm) 63399.50 60044.00 (5.29 %) 63362.65 301074.06 299662.46\n",
      "Currency: USD\n",
      "Consensus as of Oct-28-2021 8:36 AM GMT\n",
      "- EPS NORMALIZED -\n",
      "CONSENSUS ACTUAL SURPRISE\n",
      "FQ4 2020 0.08 0.05 (37.50 %)\n",
      "FQ1 2021 0.43 0.42 (2.33 %)\n",
      "FQ2 2021 0.62 0.71 12.70 %\n",
      "FQ3 2021 0.70 0.53 (24.29 %)\n",
      "1\n",
      "COPYRIGHT © 2021 S&P Global Market Intelligence, a division of S&P Global Inc. All rights reserved\n",
      "spglobal.com/marketintelligence\n",
      "\n",
      "ROYAL DUTCH SHELL PLC FQ3 2021 EARNINGS CALL | OCT 28, 2021\n",
      "Presentation\n",
      "Operator\n",
      "Welcome to the Royal Shell 2021 Q3 Results Announcement Q&A session. Today's session will be recorded.\n",
      "[Operator Instructions]\n",
      "I would like to introduce Ms. Jessica Uhl, Mr. Ben Van Beurden and Mr. Huibert Vigeveno.\n",
      "Jessica R. Uhl\n",
      "CFO & Executive Director\n",
      "Welcome, everyone, to the live Q&A on Shell's third quarter result. This quarter's performance is a\n",
      "result of the strength of our portfolio and how well positioned we are for the economic recovery. We\n",
      "are delivering sector-leading cash and making progress towards becoming a net-zero emissions energy\n",
      "business.\n",
      "Let me also reference the investor letter published yesterday by Third Point. We issued a statement to\n",
      "acknowledge our receipt of the letter and to say we have had initial conversations with Third Point through\n",
      "our Investor Relations team. We will engage further with them as we do with all of our shareholders. I\n",
      "know you'll have questions on this topic, and I hope you'll understand there isn't much more we can say at\n",
      "this moment.\n",
      "So today, Ben, Huibert and I will be answering your questions. [Operator Instructions] And with that,\n",
      "could we have the first question, please? Tracy, over to you.\n",
      "Copyright © 2021 S&P Global Market Intelligence, a division of S&P Global Inc. All Rights reserved.\n",
      "spglobal.com/marketintelligence 4\n",
      "ROYAL DUTCH SHELL PLC FQ3 2021 EARNINGS CALL | OCT 28, 2021\n"
     ]
    }
   ],
   "source": [
    "# Helper function to get Gemini query function inputs\n",
    "def get_gemini_inputs(text_df, unique_id):\n",
    "    \"\"\"\n",
    "    Retrieves information from the DataFrame based on the unique ID and outputs company, source, headline, and text.\n",
    "\n",
    "    Args:\n",
    "        text_df (pd.DataFrame): The DataFrame containing the text data.\n",
    "        unique_id (str): The unique ID to search for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing company, source, headline, and text.\n",
    "    \"\"\"\n",
    "    # Find the row with the specified unique ID\n",
    "    row = text_df[text_df['Unique_ID'] == unique_id]\n",
    "\n",
    "    # Extract the required information\n",
    "    company = row['Ticker'].values[0]\n",
    "    source = row['Source'].values[0]\n",
    "    headline = row['Article Headline'].values[0]\n",
    "    text = row['Article Text'].values[0]\n",
    "\n",
    "    return company, source, headline, text\n",
    "\n",
    "# Test function\n",
    "company, source, headline, text = get_gemini_inputs(repeated_df, unique_id)\n",
    "print(f\"Company: {company}\\n\")\n",
    "print(f\"Source: {source}\\n\")\n",
    "print(f\"Headline: {headline}\\n\")\n",
    "print(f\"Text:\\n{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "id": "eRjhvk_9Xapi",
    "outputId": "2fe3961b-a3bb-4e4a-9255-f5b040302e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sentiment Analysis of SHEL Earnings Call:\n",
      "\n",
      "**Reasoning:**\n",
      "\n",
      "The text emphasizes Shell's strong portfolio and position for economic recovery, with achievements in delivering leading cash flow and progress towards net-zero emissions. While acknowledging Third Point's letter, the focus remains on the positive performance of the company.\n",
      "\n",
      "**Category Analysis:**\n",
      "\n",
      "* **Finance:** **Positive** - The text highlights \"sector-leading cash\" and \"progress towards becoming a net-zero emissions energy business\", suggesting strong financial performance and commitment to a sustainable future.\n",
      "* **Production:** **Neutral** - Production is not explicitly discussed in the provided excerpt. \n",
      "* **Reserves / Exploration / Acquisitions / Mergers / Divestments:** **Neutral** -  No mention of specific reserves, exploration activities, or M&A transactions is made.\n",
      "* **Environment / Regulatory / Geopolitics:** **Positive** - The statement mentions \"progress towards becoming a net-zero emissions energy business\" indicating a focus on sustainability and environmental considerations.\n",
      "* **Alternative Energy / Lower Carbon:** **Positive** - The emphasis on \"net-zero emissions energy business\" directly relates to the company's commitment to alternative energy and lower carbon strategies.\n",
      "* **Oil Price / Natural Gas Price / Gasoline Price:** **Neutral** - The text does not discuss current or expected price fluctuations in oil, natural gas, or gasoline.\n",
      "\n",
      "**Summary:**\n",
      "- Finance - Positive\n",
      "- Production - Neutral\n",
      "- Reserves / Exploration / Acquisitions / Mergers / Divestments - Neutral\n",
      "- Environment / Regulatory / Geopolitics - Positive\n",
      "- Alternative Energy / Lower Carbon - Positive\n",
      "- Oil Price / Natural Gas Price / Gasoline Price - Neutral \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to query Gemini\n",
    "def query_gemini(company, source, headline, text, model):\n",
    "    \"\"\"\n",
    "    Query Gemini to perform sentiment analysis on text from various sources about a company.\n",
    "\n",
    "    Parameters:\n",
    "    company (str): The name of the company the text is about.\n",
    "    source (str): The source of the text. Valid values are \"Investment Research\", \"ProQuest\", \"SEC Filings\", \"Earnings Call Presentations\", \"Earnings Call Q&A\".\n",
    "    headline (str): The headline or title of the text.\n",
    "    text (str): The body of the text to be analyzed.\n",
    "    model: The model object used to generate content and analyze the text.\n",
    "\n",
    "    Returns:\n",
    "    str: The sentiment analysis results for predefined categories in the specified format.\n",
    "\n",
    "    The function constructs a prompt based on the source of the text and performs sentiment analysis on the given text using the provided model.\n",
    "    It analyzes the content across multiple predefined categories, determining the sentiment (Positive, Neutral, Negative) for each category.\n",
    "    If a category is not mentioned or relevant based on the text content, it is marked as 'Neutral'.\n",
    "    The final output is summarized in a specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Source Variables\n",
    "    if source == \"Investment Research\":\n",
    "        text_source = \"an analyst report\"\n",
    "        text_source2 = \"the analyst report\"\n",
    "    elif source == \"ProQuest\":\n",
    "        text_source = \"a news article\"\n",
    "        text_source2 = \"the news article\"\n",
    "    elif source == \"SEC Filings\":\n",
    "        text_source = \"an SEC filing\"\n",
    "        text_source2 = \"the SEC filing\"\n",
    "    elif source == \"Earnings Call Presentations\":\n",
    "        text_source = \"an earnings call presentation\"\n",
    "        text_source2 = \"the earnings call presentation\"\n",
    "    elif source == \"Earnings Call Q&A\":\n",
    "        text_source = \"an earnings call Q&A session\"\n",
    "        text_source2 = \"the earnings call Q&A session\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt = f\"\"\"\n",
    "Given the text from {text_source} about {company}, analyze the content and perform sentiment analysis across multiple predefined categories.\n",
    "\n",
    "Sentiment options:\n",
    "  - Positive\n",
    "  - Neutral\n",
    "  - Negative\n",
    "\n",
    "Categories:\n",
    "  - Finance\n",
    "  - Production\n",
    "  - Reserves / Exploration / Acquisitions / Mergers / Divestments\n",
    "  - Environment / Regulatory / Geopolitics\n",
    "  - Alternative Energy / Lower Carbon\n",
    "  - Oil Price / Natural Gas Price / Gasoline Price\n",
    "\n",
    "Each category should be evaluated and given a sentiment output derived from the text.\n",
    "If a category is not mentioned or relevant based on the text content, mark it as 'Neutral'.\n",
    "\n",
    "Before giving your answer, explain your reasoning and reference the article.\n",
    "After going through all the categories, provide a summary in the following format:\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "\n",
    "Example Output1:\n",
    "- Finance - Positive\n",
    "- Production - Neutral\n",
    "- Reserves / Exploration / Acquisitions / Mergers / Divestments - Negative\n",
    "- Environment / Regulatory / Geopolitics - Neutral\n",
    "- Alternative Energy / Lower Carbon - Positive\n",
    "- Oil Price / Natural Gas Price / Gasoline Price - Neutral\n",
    "\n",
    "Example Output 2:\n",
    " - Finance - Negative\n",
    " - Production - Positive\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Neutral\n",
    " - Environment / Regulatory / Geopolitics - Positive\n",
    " - Alternative Energy / Lower Carbon - Neutral\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Negative\n",
    "\n",
    "Example Output 3:\n",
    " - Finance - Neutral\n",
    " - Production - Negative\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Positive\n",
    " - Environment / Regulatory / Geopolitics - Negative\n",
    " - Alternative Energy / Lower Carbon - Positive\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Neutral\n",
    "\n",
    "Example Output 4:\n",
    " - Finance - Positive\n",
    " - Production - Neutral\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Negative\n",
    " - Environment / Regulatory / Geopolitics - Neutral\n",
    " - Alternative Energy / Lower Carbon - Negative\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Positive\n",
    "\n",
    "Example Output 5:\n",
    " - Finance - Negative\n",
    " - Production - Positive\n",
    " - Reserves / Exploration / Acquisitions / Mergers / Divestments - Neutral\n",
    " - Environment / Regulatory / Geopolitics - Negative\n",
    " - Alternative Energy / Lower Carbon - Positive\n",
    " - Oil Price / Natural Gas Price / Gasoline Price - Negative\n",
    "\n",
    "Make sure to use plain text, do not bold or bullet the output summary.\n",
    "\n",
    "The text from {text_source2} is below:\n",
    "{headline}\n",
    "{text}\n",
    "\n",
    "Remember to summarize your final answers in the following format exactly:\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "- Category - Sentiment\n",
    "\n",
    "Make sure to use plain text and stick to the given categories and sentiment options.\n",
    "DO NOT bold or bullet the output summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # print(prompt)\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Test function\n",
    "response = query_gemini(company, source, headline, text, model)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbTgA_znnYIX",
    "outputId": "b1ef5cb2-60e2-47ac-abfc-5b66e194eee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Finance': 'Positive', 'Production': 'Neutral', 'Reserves / Exploration / Acquisitions / Mergers / Divestments': 'Neutral', 'Environment / Regulatory / Geopolitics': 'Positive', 'Alternative Energy / Lower Carbon': 'Positive', 'Oil Price / Natural Gas Price / Gasoline Price': 'Neutral'}\n",
      "Did not find all categories\n"
     ]
    }
   ],
   "source": [
    "# Function to parse text\n",
    "def parse_sentiment(text, categories):\n",
    "    \"\"\"\n",
    "    Parses a given text for specified categories and their sentiments.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing categories and their sentiments.\n",
    "        categories (list of str): List of category names to look for in the text.\n",
    "\n",
    "    Returns:\n",
    "        dict or str: A dictionary with categories as keys and their corresponding sentiments as values,\n",
    "                     or \"Did not find all categories\" if any sentiment is not Positive, Neutral, or Negative.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    valid_sentiments = {\"Positive\", \"Neutral\", \"Negative\"}\n",
    "\n",
    "    for category in categories:\n",
    "        # Create a regex pattern to match the format \"- Category - Sentiment\"\n",
    "        # The category name is escaped to handle any special characters\n",
    "        pattern = rf\"- {re.escape(category)} - (\\w+)\"\n",
    "\n",
    "        # Search for the pattern in the text\n",
    "        match = re.search(pattern, text)\n",
    "\n",
    "        # If a match is found, extract the sentiment and add it to the results dictionary\n",
    "        if match:\n",
    "            sentiment = match.group(1)\n",
    "            if sentiment not in valid_sentiments:\n",
    "                return \"Did not find all categories\"\n",
    "            results[category] = sentiment\n",
    "        else:\n",
    "            return \"Did not find all categories\"\n",
    "\n",
    "    return results\n",
    "\n",
    "# Test function\n",
    "fail_text = \"\"\"\n",
    "- Finance - Positive\n",
    "- Production - Neutral\n",
    "- Reserves / Exploration / Acquisitions / Mergers / Divestments - Bad\n",
    "- Environment / Regulatory / Geopolitics - Neutral\n",
    "- Alternative Energy / Lower Carbon - Positive\n",
    "- Oil Price / Natural Gas Price / Gasoline Price - Neutral\n",
    "\"\"\"\n",
    "\n",
    "sentiment_dict = parse_sentiment(response, CATEGORIES)\n",
    "fail_sentiment = parse_sentiment(\"fail_text\", CATEGORIES)\n",
    "print(sentiment_dict)\n",
    "print(fail_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfIujTIrXj18",
    "outputId": "c6713621-57ff-4b11-9e19-ccd6675e55a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row with Unique_ID 'EP-210 7' has been updated.\n"
     ]
    }
   ],
   "source": [
    "# Function to update the csv\n",
    "def update_csv(file_path, unique_id, sentiment_dict):\n",
    "    \"\"\"\n",
    "    Updates the columns of a CSV file based on the unique ID and sentiment dictionary.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "        unique_id (str): The unique ID of the row to be updated.\n",
    "        sentiment_dict (dict): A dictionary with categories as keys and their corresponding sentiments as values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Find the index of the row with the specified unique ID\n",
    "    row_index = df[df['Unique_ID'] == unique_id].index\n",
    "\n",
    "    # Update the columns based on the sentiment dictionary\n",
    "    for category, sentiment in sentiment_dict.items():\n",
    "        df.loc[row_index, category] = sentiment\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Row with Unique_ID '{unique_id}' has been updated.\")\n",
    "\n",
    "# Test function\n",
    "update_csv(SENTIMENT_RESULTS_FILE_PATH, unique_id, sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ANJgrUqEr1tE",
    "outputId": "3c81cf36-fad8-4a43-d935-8395884731e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row with Unique_ID 'EP-210 8' has been updated.\n",
      "Row with Unique_ID 'EP-210 9' has been updated.\n",
      "Row with Unique_ID 'EP-210 10' has been updated.\n",
      "Row with Unique_ID 'EP-257 1' has been updated.\n",
      "Row with Unique_ID 'EP-257 2' has been updated.\n",
      "Row with Unique_ID 'EP-257 3' has been updated.\n",
      "Row with Unique_ID 'EP-257 4' has been updated.\n",
      "Row with Unique_ID 'EP-257 5' has been updated.\n",
      "Row with Unique_ID 'EP-257 6' has been updated.\n",
      "Row with Unique_ID 'EP-257 7' has been updated.\n",
      "Iteration: 10, Elapsed Time: 0 minutes and 56.89 seconds\n",
      "Row with Unique_ID 'EP-257 8' has been updated.\n",
      "Row with Unique_ID 'EP-257 9' has been updated.\n",
      "Row with Unique_ID 'EP-257 10' has been updated.\n",
      "Row with Unique_ID 'EP-98 1' has been updated.\n",
      "Row with Unique_ID 'EP-98 2' has been updated.\n",
      "Row with Unique_ID 'EP-98 3' has been updated.\n",
      "Row with Unique_ID 'EP-98 4' has been updated.\n",
      "Row with Unique_ID 'EP-98 5' has been updated.\n",
      "Row with Unique_ID 'EP-98 6' has been updated.\n",
      "Row with Unique_ID 'EP-98 7' has been updated.\n",
      "Iteration: 20, Elapsed Time: 1 minutes and 56.30 seconds\n",
      "Row with Unique_ID 'EP-98 8' has been updated.\n",
      "Row with Unique_ID 'EP-98 9' has been updated.\n",
      "Row with Unique_ID 'EP-98 10' has been updated.\n",
      "Row with Unique_ID 'EP-33 1' has been updated.\n",
      "Row with Unique_ID 'EP-33 2' has been updated.\n",
      "Row with Unique_ID 'EP-33 3' has been updated.\n",
      "Row with Unique_ID 'EP-33 4' has been updated.\n",
      "Row with Unique_ID 'EP-33 5' has been updated.\n",
      "Row with Unique_ID 'EP-33 6' has been updated.\n",
      "Row with Unique_ID 'EP-33 7' has been updated.\n",
      "Iteration: 30, Elapsed Time: 2 minutes and 55.19 seconds\n",
      "Row with Unique_ID 'EP-33 8' has been updated.\n",
      "Row with Unique_ID 'EP-33 9' has been updated.\n",
      "Row with Unique_ID 'EP-33 10' has been updated.\n",
      "Row with Unique_ID 'EP-10 1' has been updated.\n",
      "Row with Unique_ID 'EP-10 2' has been updated.\n",
      "Row with Unique_ID 'EP-10 3' has been updated.\n",
      "Row with Unique_ID 'EP-10 4' has been updated.\n",
      "Row with Unique_ID 'EP-10 5' has been updated.\n",
      "Row with Unique_ID 'EP-10 6' has been updated.\n",
      "Row with Unique_ID 'EP-10 7' has been updated.\n",
      "Iteration: 40, Elapsed Time: 4 minutes and 5.47 seconds\n",
      "Row with Unique_ID 'EP-10 8' has been updated.\n",
      "Row with Unique_ID 'EP-10 9' has been updated.\n",
      "Row with Unique_ID 'EP-10 10' has been updated.\n",
      "Row with Unique_ID 'EQ-167 1' has been updated.\n",
      "Row with Unique_ID 'EQ-167 2' has been updated.\n",
      "Row with Unique_ID 'EQ-167 3' has been updated.\n",
      "Row with Unique_ID 'EQ-167 4' has been updated.\n",
      "Row with Unique_ID 'EQ-167 5' has been updated.\n",
      "Row with Unique_ID 'EQ-167 6' has been updated.\n",
      "Row with Unique_ID 'EQ-167 7' has been updated.\n",
      "Iteration: 50, Elapsed Time: 5 minutes and 3.87 seconds\n",
      "Row with Unique_ID 'EQ-167 8' has been updated.\n",
      "Error encountered: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.. Retry 1/5\n",
      "Row with Unique_ID 'EQ-167 9' has been updated.\n",
      "Row with Unique_ID 'EQ-167 10' has been updated.\n",
      "Row with Unique_ID 'EQ-7 1' has been updated.\n",
      "Row with Unique_ID 'EQ-7 2' has been updated.\n",
      "Row with Unique_ID 'EQ-7 3' has been updated.\n",
      "Row with Unique_ID 'EQ-7 4' has been updated.\n",
      "Row with Unique_ID 'EQ-7 5' has been updated.\n",
      "Row with Unique_ID 'EQ-7 6' has been updated.\n",
      "Row with Unique_ID 'EQ-7 7' has been updated.\n",
      "Iteration: 60, Elapsed Time: 6 minutes and 9.16 seconds\n",
      "Row with Unique_ID 'EQ-7 8' has been updated.\n",
      "Row with Unique_ID 'EQ-7 9' has been updated.\n",
      "Row with Unique_ID 'EQ-7 10' has been updated.\n",
      "Row with Unique_ID 'EQ-115 1' has been updated.\n",
      "Row with Unique_ID 'EQ-115 2' has been updated.\n",
      "Row with Unique_ID 'EQ-115 3' has been updated.\n",
      "Row with Unique_ID 'EQ-115 4' has been updated.\n",
      "Row with Unique_ID 'EQ-115 5' has been updated.\n",
      "Row with Unique_ID 'EQ-115 6' has been updated.\n",
      "Row with Unique_ID 'EQ-115 7' has been updated.\n",
      "Iteration: 70, Elapsed Time: 7 minutes and 10.88 seconds\n",
      "Row with Unique_ID 'EQ-115 8' has been updated.\n",
      "Row with Unique_ID 'EQ-115 9' has been updated.\n",
      "Row with Unique_ID 'EQ-115 10' has been updated.\n",
      "Row with Unique_ID 'EQ-72 1' has been updated.\n",
      "Row with Unique_ID 'EQ-72 2' has been updated.\n",
      "Row with Unique_ID 'EQ-72 3' has been updated.\n",
      "Row with Unique_ID 'EQ-72 4' has been updated.\n",
      "Row with Unique_ID 'EQ-72 5' has been updated.\n",
      "Row with Unique_ID 'EQ-72 6' has been updated.\n",
      "Row with Unique_ID 'EQ-72 7' has been updated.\n",
      "Iteration: 80, Elapsed Time: 8 minutes and 2.21 seconds\n",
      "Row with Unique_ID 'EQ-72 8' has been updated.\n",
      "Row with Unique_ID 'EQ-72 9' has been updated.\n",
      "Row with Unique_ID 'EQ-72 10' has been updated.\n",
      "Row with Unique_ID 'EQ-132 1' has been updated.\n",
      "Row with Unique_ID 'EQ-132 2' has been updated.\n",
      "Row with Unique_ID 'EQ-132 3' has been updated.\n",
      "Row with Unique_ID 'EQ-132 4' has been updated.\n",
      "Row with Unique_ID 'EQ-132 5' has been updated.\n",
      "Row with Unique_ID 'EQ-132 6' has been updated.\n",
      "Row with Unique_ID 'EQ-132 7' has been updated.\n",
      "Iteration: 90, Elapsed Time: 8 minutes and 55.19 seconds\n",
      "Row with Unique_ID 'EQ-132 8' has been updated.\n",
      "Row with Unique_ID 'EQ-132 9' has been updated.\n",
      "Row with Unique_ID 'EQ-132 10' has been updated.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "unique_id = find_first_unique_id_with_empty_values(SENTIMENT_RESULTS_FILE_PATH, CATEGORIES)\n",
    "count = 0\n",
    "max_tries = 5\n",
    "\n",
    "# Iterate through the CSV using the functions\n",
    "while unique_id:\n",
    "    retries = 0\n",
    "    success = False\n",
    "\n",
    "    # There are multiple errors that can happen, many of them simply need another try\n",
    "    while retries < max_tries and not success:\n",
    "        try:\n",
    "            # Get gemini inputs\n",
    "            company, source, headline, text = get_gemini_inputs(repeated_df, unique_id)\n",
    "\n",
    "            # Query Gemini\n",
    "            response = query_gemini(company, source, headline, text, model)\n",
    "\n",
    "            # Parse text\n",
    "            sentiment_dict = parse_sentiment(response, CATEGORIES)\n",
    "\n",
    "            # Update the csv\n",
    "            update_csv(SENTIMENT_RESULTS_FILE_PATH, unique_id, sentiment_dict)\n",
    "\n",
    "            success = True\n",
    "\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Error encountered: {e}. Retry {retries}/{max_tries}\")\n",
    "\n",
    "            if retries >= max_tries:\n",
    "                print(f\"Failed to process unique_id {unique_id} after {max_tries} attempts. Stopping.\")\n",
    "                # Exit both loops\n",
    "                unique_id = None\n",
    "                break\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Get an update every 10 rows\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        minutes, seconds = divmod(elapsed_time, 60)\n",
    "        print(f\"Iteration: {count}, Elapsed Time: {int(minutes)} minutes and {seconds:.2f} seconds\")\n",
    "\n",
    "    # Find the next empty row\n",
    "    unique_id = find_first_unique_id_with_empty_values(SENTIMENT_RESULTS_FILE_PATH, CATEGORIES)\n",
    "\n",
    "    # Test print statements\n",
    "    # print(unique_id)\n",
    "    # print(f\"Company: {company}\\n\")\n",
    "    # print(f\"Source: {source}\\n\")\n",
    "    # print(f\"Headline: {headline}\\n\")\n",
    "    # print(f\"Text:\\n{text}\")\n",
    "    # print(response)\n",
    "    # print(sentiment_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (capstone)",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
